{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Introducci칩n a APIs de Modelos de Lenguaje\n",
    "\n",
    "## Objetivos de Aprendizaje\n",
    "\n",
    "En este cuaderno vas a aprender:\n",
    "- Qu칠 es una API y c칩mo nos permite acceder a modelos de lenguaje grandes (LLMs)\n",
    "- C칩mo configurar y autenticar tu conexi칩n con OpenAI\n",
    "- T칠cnicas de prompting b치sicas para extraer informaci칩n estructurada\n",
    "- Casos de uso pr치cticos del procesamiento del lenguaje natural\n",
    "\n",
    "## 쯈u칠 es una API?\n",
    "\n",
    "Una **API** (Application Programming Interface) es una interfaz que permite que dos sistemas se comuniquen entre s칤. En nuestro caso, nos permite enviar texto a un modelo de lenguaje (como GPT-4) y recibir una respuesta procesada.\n",
    "\n",
    "**Analog칤a**: Imaginate que est치s en un restaurante. Vos sos el cliente (tu programa), el mozo es la API, y la cocina es el modelo de lenguaje. Vos le ped칤s algo al mozo (envi치s un prompt), el mozo se lo lleva a la cocina (el modelo procesa), y te trae de vuelta el plato (la respuesta).\n",
    "\n",
    "## Prerequisitos\n",
    "\n",
    "Para usar este cuaderno necesit치s:\n",
    "1. Una cuenta en OpenAI (https://platform.openai.com)\n",
    "2. Una API key (se genera en https://platform.openai.com/account/api-keys)\n",
    "3. Cr칠dito en tu cuenta de OpenAI (hay planes gratuitos para empezar)\n",
    "\n",
    "**Nota sobre costos**: Los modelos como `gpt-4o-mini` son muy econ칩micos (menos de $0.01 por cada 1000 palabras procesadas). Para este curso, con $5 USD ten칠s suficiente para todos los ejercicios."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## Configuraci칩n del Entorno\n",
    "\n",
    "Primero instalamos la librer칤a de OpenAI y configuramos la autenticaci칩n. Este c칩digo detecta autom치ticamente si est치s en Google Colab o trabajando localmente, y carga la API key desde el lugar apropiado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalamos la librer칤a oficial de OpenAI\n",
    "!pip install --upgrade openai --quiet\n",
    "\n",
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "# Detectamos si estamos en Google Colab o en entorno local\n",
    "IN_COLAB = False\n",
    "try:\n",
    "    import google.colab\n",
    "    from google.colab import userdata\n",
    "    IN_COLAB = True\n",
    "except Exception:\n",
    "    IN_COLAB = False\n",
    "\n",
    "# Cargamos la API key seg칰n el entorno\n",
    "OPENAI_API_KEY = None\n",
    "if IN_COLAB:\n",
    "    # En Colab: usar secrets (icono de llave en la barra lateral)\n",
    "    try:\n",
    "        OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
    "    except Exception:\n",
    "        OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "else:\n",
    "    # En local: usar variable de entorno o archivo .env\n",
    "    OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "if not OPENAI_API_KEY:\n",
    "    raise ValueError(\n",
    "        'OPENAI_API_KEY no encontrada.\\n'\n",
    "        'En Colab: agregala en Secrets (icono de llave)\\n'\n",
    "        'En local: agregala a tus variables de entorno o archivo .env'\n",
    "    )\n",
    "\n",
    "print(f\"API key cargada correctamente. Entorno: {'Colab' if IN_COLAB else 'Local'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "### Notas T칠cnicas: Configuraci칩n de API Key\n",
    "\n",
    "**En Google Colab**:\n",
    "1. Clic en el icono de llave en la barra lateral izquierda\n",
    "2. Agregar un nuevo secret con nombre `OPENAI_API_KEY`\n",
    "3. Pegar tu API key como valor\n",
    "\n",
    "**En entorno local**:\n",
    "```bash\n",
    "# Opci칩n 1: Variable de entorno (Linux/Mac)\n",
    "export OPENAI_API_KEY='tu-api-key-aqui'\n",
    "\n",
    "# Opci칩n 2: Archivo .env\n",
    "# Crear archivo .env en la ra칤z del proyecto:\n",
    "OPENAI_API_KEY=tu-api-key-aqui\n",
    "```\n",
    "\n",
    "**Seguridad**: Nunca subas tu API key a GitHub o la compartas p칰blicamente. Las API keys son como contrase침as y dan acceso a tu cuenta (y cr칠dito) de OpenAI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "## Funci칩n Auxiliar: get_completion()\n",
    "\n",
    "Creamos una funci칩n helper que simplifica el env칤o de prompts a la API. Esta funci칩n encapsula toda la l칩gica de comunicaci칩n y nos permite concentrarnos en el contenido de nuestros prompts.\n",
    "\n",
    "### Par치metros configurables:\n",
    "\n",
    "- **prompt** (str): El texto que queremos enviar al modelo\n",
    "- **model** (str): Qu칠 modelo usar. Opciones comunes:\n",
    "  - `gpt-4o-mini`: R치pido, econ칩mico, ideal para la mayor칤a de tareas\n",
    "  - `gpt-4o`: M치s potente, mejor razonamiento, m치s caro\n",
    "  - `gpt-4-turbo`: Balance entre velocidad y capacidad\n",
    "- **temperature** (float, 0-2): Controla la aleatoriedad de las respuestas\n",
    "  - `0.0`: Determin칤stico, siempre responde igual (ideal para extracci칩n de datos)\n",
    "  - `0.7`: Balance (bueno para texto general)\n",
    "  - `1.5-2.0`: Creativo, m치s variado (칰til para generaci칩n creativa)\n",
    "\n",
    "**Recomendaci칩n**: Para tareas de extracci칩n y an치lisis, us치 temperature=0. Para generaci칩n creativa, prob치 con valores entre 0.7 y 1.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt, model=\"gpt-4o-mini\", temperature=0):\n",
    "    \"\"\"\n",
    "    Env칤a un prompt a la API de OpenAI y devuelve la respuesta.\n",
    "    \n",
    "    Par치metros:\n",
    "    -----------\n",
    "    prompt : str\n",
    "        El texto que queremos enviar al modelo\n",
    "    model : str, default=\"gpt-4o-mini\"\n",
    "        Modelo a utilizar (gpt-4o-mini es econ칩mico y efectivo)\n",
    "    temperature : float, default=0\n",
    "        Grado de aleatoriedad (0 = determin칤stico, 2 = muy creativo)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    str\n",
    "        La respuesta generada por el modelo\n",
    "    \"\"\"\n",
    "    # Creamos el cliente de OpenAI\n",
    "    client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "    \n",
    "    # Estructuramos el mensaje como conversaci칩n\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    \n",
    "    # Hacemos el request a la API\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature\n",
    "    )\n",
    "    \n",
    "    # Extraemos y devolvemos solo el contenido de la respuesta\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "## Ejemplo 1: An치lisis de Sentimiento en Reviews\n",
    "\n",
    "Vamos a analizar una review de MercadoLibre y extraer informaci칩n estructurada. Este es un caso de uso muy com칰n en comercio electr칩nico.\n",
    "\n",
    "**Objetivo**: Dado un comentario de un cliente, queremos extraer autom치ticamente:\n",
    "- El sentimiento general (positivo/negativo/neutro)\n",
    "- Si el cliente est치 enojado\n",
    "- Qu칠 producto compr칩\n",
    "- Qu칠 marca es\n",
    "\n",
    "Esto permite procesar miles de reviews autom치ticamente para detectar problemas, medir satisfacci칩n, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review real de un producto (simulada pero realista)\n",
    "review_producto = \"\"\"\n",
    "Compr칠 estos auriculares porque ten칤an buenas rese침as y el precio era razonable.\n",
    "La verdad que llegaron r치pido, en dos d칤as ya los ten칤a. El sonido es bastante bueno\n",
    "para el precio, se escucha claro y los graves est치n bien. Lo que no me gust칩 es que\n",
    "despu칠s de un mes de uso, el auricular derecho empez칩 a sonar m치s bajo que el izquierdo.\n",
    "Contact칠 al vendedor y me mandaron otro par sin problema. El servicio de atenci칩n fue\n",
    "excelente, respondieron al toque y resolvieron todo. En general estoy conforme, pero\n",
    "esperaba que duraran m치s antes de tener problemas.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "### Construcci칩n del Prompt\n",
    "\n",
    "Un buen prompt es espec칤fico y claro sobre qu칠 formato queremos en la respuesta. Ac치 aplicamos varias t칠cnicas:\n",
    "\n",
    "1. **Instrucciones claras**: Describimos exactamente qu칠 queremos extraer\n",
    "2. **Formato estructurado**: Pedimos JSON para poder parsear program치ticamente\n",
    "3. **Manejo de casos edge**: Indicamos qu칠 hacer si falta informaci칩n\n",
    "4. **Delimitadores**: Usamos triple comillas para delimitar el texto a analizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Analiza la siguiente review de producto y extrae la informaci칩n en formato JSON.\n",
    "\n",
    "Informaci칩n a extraer:\n",
    "- Sentimiento: positivo, negativo o neutro\n",
    "- Enojado: true o false (쯘l cliente expresa enojo?)\n",
    "- Producto: qu칠 producto compr칩\n",
    "- Problema: si hubo alg칰n problema, cu치l fue\n",
    "- Calidad_atencion: c칩mo fue el servicio al cliente\n",
    "\n",
    "Si alguna informaci칩n no est치 presente, us치 \"no_especificado\".\n",
    "El campo \"Enojado\" debe ser booleano (true/false).\n",
    "\n",
    "Review: ```{review_producto}```\n",
    "\n",
    "Responde 칰nicamente con el JSON, sin texto adicional.\n",
    "\"\"\"\n",
    "\n",
    "respuesta = get_completion(prompt)\n",
    "print(\"AN츼LISIS DE LA REVIEW:\")\n",
    "print(respuesta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "### An치lisis del Resultado\n",
    "\n",
    "Observ치 que el modelo pudo:\n",
    "1. Identificar que el sentimiento es mixto/neutro (hay aspectos positivos y negativos)\n",
    "2. Detectar que no hay enojo expl칤cito\n",
    "3. Extraer el producto espec칤fico\n",
    "4. Identificar el problema t칠cnico\n",
    "5. Valorar positivamente la atenci칩n al cliente\n",
    "\n",
    "Todo esto en formato JSON que podemos usar program치ticamente:\n",
    "\n",
    "```python\n",
    "import json\n",
    "datos = json.loads(respuesta)\n",
    "print(datos['Sentimiento'])  # Acceso a los datos\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "## Ejemplo 2: An치lisis de Noticias Period칤sticas\n",
    "\n",
    "Ahora vamos a trabajar con un texto period칤stico y extraer informaci칩n estructurada relevante. Este tipo de an치lisis es 칰til para:\n",
    "- Sistemas de monitoreo de medios\n",
    "- Agregadores de noticias\n",
    "- An치lisis de cobertura medi치tica\n",
    "- Detecci칩n de temas trending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nota period칤stica simulada\n",
    "noticia = \"\"\"\n",
    "BUENOS AIRES - El Ministerio de Cultura anunci칩 ayer la apertura de tres nuevos\n",
    "espacios culturales en barrios de la zona sur de la ciudad. Los centros culturales\n",
    "se ubicar치n en Parque Patricios, Pompeya y Nueva Pompeya, y comenzar치n a funcionar\n",
    "en marzo de 2024.\n",
    "\n",
    "Seg칰n inform칩 la ministra de Cultura, Mar칤a Rodr칤guez, los espacios contar치n con\n",
    "talleres gratuitos de m칰sica, teatro, danza y artes visuales. \"Es fundamental\n",
    "descentralizar la oferta cultural y llegar a todos los barrios de la ciudad\",\n",
    "afirm칩 la funcionaria durante la conferencia de prensa.\n",
    "\n",
    "La inversi칩n total del proyecto asciende a $450 millones y se espera que beneficie\n",
    "directamente a m치s de 15.000 vecinos de la zona sur. Las inscripciones para los\n",
    "talleres comenzar치n en febrero a trav칠s de la web oficial del Ministerio.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_noticia = f\"\"\"\n",
    "Analiza la siguiente noticia y extrae la informaci칩n clave en formato JSON:\n",
    "\n",
    "- Tema_principal: tema central de la noticia\n",
    "- Ubicacion: d칩nde ocurre el hecho\n",
    "- Fecha_evento: cu치ndo ocurrir치 o ocurri칩\n",
    "- Protagonistas: personas u organizaciones mencionadas\n",
    "- Datos_numericos: cifras relevantes (monto, cantidad de personas, etc.)\n",
    "- Categoria: clasific치 en pol칤tica, econom칤a, cultura, sociedad, deportes, tecnolog칤a\n",
    "\n",
    "Si no hay informaci칩n, us치 \"no_especificado\".\n",
    "\n",
    "Noticia: ```{noticia}```\n",
    "\n",
    "Devuelve solo el JSON.\n",
    "\"\"\"\n",
    "\n",
    "analisis_noticia = get_completion(prompt_noticia)\n",
    "print(\"AN츼LISIS DE LA NOTICIA:\")\n",
    "print(analisis_noticia)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-14",
   "metadata": {},
   "source": [
    "## Ejemplo 3: Clasificaci칩n de Comentarios de Redes Sociales\n",
    "\n",
    "Las redes sociales generan millones de comentarios por d칤a. Los LLMs pueden ayudarnos a clasificarlos autom치ticamente seg칰n diferentes criterios.\n",
    "\n",
    "**Caso de uso**: Moderaci칩n de contenido, an치lisis de opini칩n p칰blica, detecci칩n de toxicidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colecci칩n de comentarios simulados\n",
    "comentarios = [\n",
    "    \"Excelente la nueva temporada! La mejor serie que vi en a침os 游댠\",\n",
    "    \"No entiendo por qu칠 le dan tanto hype, es bastante meh\",\n",
    "    \"Alguien sabe d칩nde puedo conseguir las zapatillas que usa el prota?\",\n",
    "    \"SPOILER: No puedo creer que mataron a ese personaje!!! 游땴\",\n",
    "    \"Qu칠 basura, perd칤 3 horas de mi vida viendo esto\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Procesamos m칰ltiples comentarios\n",
    "print(\"CLASIFICACI칍N DE COMENTARIOS:\\n\")\n",
    "\n",
    "for i, comentario in enumerate(comentarios, 1):\n",
    "    prompt_comentario = f\"\"\"\n",
    "    Clasifica este comentario seg칰n:\n",
    "    - Sentimiento: positivo, negativo o neutral\n",
    "    - Tipo: opinion, pregunta, spoiler, spam, otro\n",
    "    - Toxicidad: baja, media, alta\n",
    "    \n",
    "    Comentario: ```{comentario}```\n",
    "    \n",
    "    Devuelve solo un JSON con esas tres claves.\n",
    "    \"\"\"\n",
    "    \n",
    "    resultado = get_completion(prompt_comentario)\n",
    "    print(f\"Comentario {i}: {comentario}\")\n",
    "    print(f\"An치lisis: {resultado}\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-17",
   "metadata": {},
   "source": [
    "## Experimentaci칩n: Prob치 Modificar los Par치metros\n",
    "\n",
    "Esta secci칩n est치 dise침ada para que experimentes con diferentes configuraciones y veas c칩mo cambian los resultados.\n",
    "\n",
    "### Ejercicio 1: Efecto de la temperatura\n",
    "\n",
    "Ejecut치 la siguiente celda varias veces cambiando el par치metro `temperature` y observ치 c칩mo var칤an las respuestas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zona de experimentaci칩n - Modifica estos valores\n",
    "TEMPERATURA = 0.0  # Prob치 con: 0.0, 0.5, 1.0, 1.5\n",
    "MODELO = \"gpt-4o-mini\"  # Prob치 con: \"gpt-4o-mini\", \"gpt-4o\"\n",
    "\n",
    "texto_ejemplo = \"El partido estuvo incre칤ble, se defini칩 en el 칰ltimo minuto.\"\n",
    "\n",
    "prompt_exp = f\"\"\"\n",
    "Reescribe este texto de tres formas diferentes manteniendo el significado:\n",
    "{texto_ejemplo}\n",
    "\"\"\"\n",
    "\n",
    "print(f\"Usando temperatura={TEMPERATURA} y modelo={MODELO}\")\n",
    "print(\"\\nResultado:\")\n",
    "print(get_completion(prompt_exp, model=MODELO, temperature=TEMPERATURA))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-19",
   "metadata": {},
   "source": [
    "### Ejercicio 2: Tus propios ejemplos\n",
    "\n",
    "Ahora prob치 con tus propios textos. Puede ser:\n",
    "- Un comentario de YouTube\n",
    "- Una review de un producto\n",
    "- Un titular de noticia\n",
    "- Un tweet\n",
    "- Un fragmento de conversaci칩n\n",
    "\n",
    "Modific치 las variables y experiment치 con diferentes prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TU TURNO: Reemplaza este texto con el que quieras analizar\n",
    "mi_texto = \"\"\"\n",
    "Ac치 pega tu texto para analizar...\n",
    "\"\"\"\n",
    "\n",
    "# Modifica este prompt seg칰n lo que quieras hacer\n",
    "mi_prompt = f\"\"\"\n",
    "Analiza este texto y decime:\n",
    "1. De qu칠 se trata\n",
    "2. Qu칠 sentimiento expresa\n",
    "3. Si hay algo interesante o relevante\n",
    "\n",
    "Texto: ```{mi_texto}```\n",
    "\"\"\"\n",
    "\n",
    "print(get_completion(mi_prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-21",
   "metadata": {},
   "source": [
    "## Resumen y Conceptos Clave\n",
    "\n",
    "### 쯈u칠 aprendimos?\n",
    "\n",
    "1. **APIs de LLMs**: Interfaces que nos permiten acceder a modelos de lenguaje potentes sin necesidad de entrenarlos nosotros\n",
    "\n",
    "2. **Configuraci칩n segura**: C칩mo manejar API keys sin exponerlas en el c칩digo\n",
    "\n",
    "3. **Funci칩n wrapper**: `get_completion()` simplifica el uso de la API\n",
    "\n",
    "4. **Par치metros configurables**:\n",
    "   - `model`: Qu칠 modelo usar (calidad vs costo vs velocidad)\n",
    "   - `temperature`: Control de creatividad/determinismo\n",
    "\n",
    "5. **Prompting estructurado**: T칠cnicas para obtener respuestas en formato JSON 칰til\n",
    "\n",
    "6. **Casos de uso reales**: Reviews, noticias, comentarios de redes sociales\n",
    "\n",
    "### T칠cnicas de Prompting Aprendidas\n",
    "\n",
    "- **Instrucciones claras**: Especificar exactamente qu칠 queremos\n",
    "- **Formato de salida**: Pedir JSON para procesar program치ticamente\n",
    "- **Manejo de casos edge**: Indicar qu칠 hacer con informaci칩n faltante\n",
    "- **Delimitadores**: Usar ``` o \"\"\" para marcar el texto a procesar\n",
    "- **Ejemplos espec칤ficos**: Dar formato de respuesta esperada\n",
    "\n",
    "### Pr칩ximos pasos\n",
    "\n",
    "En el siguiente cuaderno vamos a profundizar en:\n",
    "- **System prompts**: C칩mo definir el comportamiento del asistente\n",
    "- **Conversaciones multi-turno**: Mantener contexto entre mensajes\n",
    "- **Roles**: Diferencia entre system, user y assistant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-22",
   "metadata": {},
   "source": [
    "## Glosario\n",
    "\n",
    "**API (Application Programming Interface)**: Conjunto de definiciones y protocolos que permite que dos sistemas se comuniquen\n",
    "\n",
    "**LLM (Large Language Model)**: Modelo de lenguaje entrenado con grandes cantidades de texto que puede generar, analizar y transformar texto\n",
    "\n",
    "**Prompt**: Instrucci칩n o pregunta que le damos al modelo de lenguaje\n",
    "\n",
    "**Temperature**: Par치metro que controla la aleatoriedad de las respuestas (0=determin칤stico, 2=muy creativo)\n",
    "\n",
    "**Token**: Unidad b치sica de procesamiento de texto (aproximadamente 0.75 palabras en espa침ol)\n",
    "\n",
    "**JSON**: Formato de intercambio de datos estructurado, f치cil de leer para humanos y m치quinas\n",
    "\n",
    "**Endpoint**: URL espec칤fica de una API donde enviamos nuestros requests\n",
    "\n",
    "**Request**: Petici칩n que hacemos a la API con nuestro prompt\n",
    "\n",
    "**Response**: Respuesta que recibimos de la API despu칠s de procesar nuestro request"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-23",
   "metadata": {},
   "source": [
    "## Preguntas Frecuentes\n",
    "\n",
    "**P: 쯇or qu칠 usar temperature=0 en algunos casos?**\n",
    "\n",
    "R: Cuando necesitamos respuestas consistentes y determin칤sticas, especialmente para extracci칩n de datos estructurados. Con temperature=0, el modelo siempre va a dar la misma respuesta para el mismo prompt.\n",
    "\n",
    "---\n",
    "\n",
    "**P: 쮺u치nto cuesta usar la API de OpenAI?**\n",
    "\n",
    "R: Depende del modelo. GPT-4o-mini es el m치s econ칩mico (~$0.15 por mill칩n de tokens de entrada). Para este curso, $5 USD es m치s que suficiente.\n",
    "\n",
    "---\n",
    "\n",
    "**P: 쯈u칠 pasa si mi API key se vence o me quedo sin cr칠dito?**\n",
    "\n",
    "R: La API va a devolver un error. Podes cargar m치s cr칠dito en tu cuenta de OpenAI o esperar a que se renueve si ten칠s un plan de subscripci칩n.\n",
    "\n",
    "---\n",
    "\n",
    "**P: 쯇uedo usar estos modelos sin conexi칩n a internet?**\n",
    "\n",
    "R: No, la API de OpenAI requiere conexi칩n. Sin embargo, en clases posteriores vamos a ver Ollama, que permite ejecutar modelos localmente.\n",
    "\n",
    "---\n",
    "\n",
    "**P: 쮼l modelo tiene acceso a internet o a informaci칩n actualizada?**\n",
    "\n",
    "R: No, el modelo solo tiene conocimiento hasta su fecha de entrenamiento (t칤picamente varios meses atr치s). En el 칰ltimo cuaderno del m칩dulo veremos c칩mo darle acceso a informaci칩n actualizada mediante b칰squeda web."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-24",
   "metadata": {},
   "source": [
    "## Referencias y Recursos Adicionales\n",
    "\n",
    "**Documentaci칩n oficial**:\n",
    "- OpenAI API Documentation: https://platform.openai.com/docs\n",
    "- Gu칤a de modelos: https://platform.openai.com/docs/models\n",
    "- Pricing: https://openai.com/pricing\n",
    "\n",
    "**Recursos recomendados**:\n",
    "- Curso de DeepLearning.AI sobre Prompt Engineering (gratuito)\n",
    "- OpenAI Cookbook: Ejemplos pr치cticos en GitHub\n",
    "- Comunidad de OpenAI en Discord\n",
    "\n",
    "**Papers relevantes**:\n",
    "- \"Language Models are Few-Shot Learners\" (GPT-3)\n",
    "- \"Training language models to follow instructions\" (InstructGPT)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
