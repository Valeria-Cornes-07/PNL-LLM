{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Actalizando la información de los LLMs\n",
        "\n",
        "Una gran limitación de los  LLMS es que almacenan toda la información en sus parámetros que son ajustados en el momento de entrenamiento. Dentro de la memoria de ChatGPT hay almacenada una gran cantidad de datos de la realidad que:\n",
        "* Se repitieron en los textos de entrenamiento de la etapa no supervisada (predicción del texto que sigue)\n",
        "\n",
        "* Fueron parte de las respuestas escritas por humanos en la etapa supervisada\n",
        "\n",
        "* Fueron etiquetadas por un humano como correctas (:thumbsup:) en la etapa de RLHF\n",
        "\n",
        "Miren el siguiente ejemplo:\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZRTMPFP2vGIU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://i.ibb.co/wp3vrv5/Screen-Shot-2023-09-17-at-17-03-57.png\" width=\"500px\" />\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "u28gLBDJwVzt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pero ¿Qué pasa si necesitamos datos recientes?\n",
        "\n",
        "<img src=\"https://i.ibb.co/rMj3ScT/Whats-App-Image-2023-09-13-at-13-36-03-1.jpg\" width=\"500px\" />"
      ],
      "metadata": {
        "id": "P_LP9EDnxEQl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "# Tiene formato de código\n",
        "```\n",
        "\n",
        "Desde la aparición de los LLMs cobraron gran importancia las herramientas capaces de proveer información textual en tiempo real, como las bases de datos vectoriales (que vamos a ver más adelante en el curso) y los motores de búsqueda consumidos a través de APIs como Bing y <a href=\"https://serpapi.com/\">SERP API</a>, que utiliza web scraping de los resultados orgánicos de Google.\n",
        "\n",
        "Existen aplicaciones para usuarios finales que ya permiten combinar la capacidad de razonamiento de los LLMs con estos grandes índices de información actualizada como https://www.bing.com/chat y https://www.perplexity.ai/"
      ],
      "metadata": {
        "id": "1TD1AN2yyP3R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://i.ibb.co/VQ27VQZ/Whats-App-Image-2023-09-13-at-13-36-03.jpg\" width=\"500px\" />\n"
      ],
      "metadata": {
        "id": "Bb606YkDzneD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ejercicio\n",
        "\n",
        "Les proponemos utilizar las APIs de SERP y OpenAI para responder preguntas de actualidad, como por ejemplo ¿Quién ganó las elecciones de Argentina 2023? Exploremos un sistema capaz de responder a cualquier pregunta de actualidad.\n",
        "\n",
        "Para poder resolver este ejercicio vamos a utilizar dos sistemas externos: SERP API y OpenAI. Ambos tienen consumos de prueba que se pueden utilizar para explorar, pero cuando integramos este tipo de servicios a nuestras tenemos que considerar:\n",
        "\n",
        "1) Los costos: https://serpapi.com/pricing // https://openai.com/pricing\n",
        "\n",
        "2) Seguridad: ¡Cuidado! Las claves privadas son lo único que se necesita para acceder con una identidad. En los sistemas productivos las claves se encuentran en un archivo de configuración (.env) y JAMÁS se deben subir a los repositorios de código como git. Normalmente se excluye al .env del repositorio utilizando el archivo .gitignore\n"
      ],
      "metadata": {
        "id": "J4k8usXD0IN5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalamos las librerías\n",
        "!pip install google-search-results openai"
      ],
      "metadata": {
        "id": "y1I3fR-lWxtl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "872a1082-85dd-4a0b-c41f-c8ea236f1a24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-search-results in /usr/local/lib/python3.12/dist-packages (2.4.2)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (1.100.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from google-search-results) (2.32.4)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.10.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.11.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.14.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->google-search-results) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->google-search-results) (2.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Paso 1. Registrarse a SERP API y Open AI para obetener las siguientes claves\n",
        "\n",
        "from google.colab import userdata\n",
        "\n",
        "SERP_API_KEY = userdata.get(\"SERP_API_KEY\")\n",
        "#OPENAI_ORGANIZATION = userdata.get(\"OPENAI_ORGANIZATION\")\n",
        "OPENAI_API_KEY = userdata.get(\"OPENAI_API_KEY\")"
      ],
      "metadata": {
        "id": "J89ahGqro-Km"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from itertools import islice\n",
        "from dataclasses import dataclass\n",
        "from serpapi import GoogleSearch\n",
        "\n",
        "@dataclass(frozen=True)\n",
        "class SnippetCitation:\n",
        "    Url: str\n",
        "    Title: str\n",
        "    Snippet: str\n",
        "\n",
        "def serp_results(query: str, num=5, api_key=SERP_API_KEY):\n",
        "  params = {\n",
        "      \"engine\": \"google\",\n",
        "      \"q\": query,\n",
        "      \"api_key\": api_key,\n",
        "      \"num\":num\n",
        "  }\n",
        "  search = GoogleSearch(params)\n",
        "  res = search.get_dict()\n",
        "  organic_results = res.get(\"organic_results\", []) # Add this line to safely access the key\n",
        "  return_results = []\n",
        "  for result in organic_results:\n",
        "      try:\n",
        "        return_results.append(SnippetCitation(Url=result[\"link\"], Title=result[\"title\"], Snippet=result[\"snippet\"]))\n",
        "      except Exception as e:\n",
        "          print(e)\n",
        "  return return_results"
      ],
      "metadata": {
        "id": "hvmGwWXXwRce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "serp_res = serp_results(\"¿Cual es el nombre del Papa?\")\n",
        "serp_res"
      ],
      "metadata": {
        "id": "Rkwwb-E7asDf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2acd9cb-5bd7-4fa7-e501-f312afc63d67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[SnippetCitation(Url='https://es.wikipedia.org/wiki/Francisco_(papa)', Title='Francisco (papa) - Wikipedia, la enciclopedia libre', Snippet='Jorge Mario Bergoglio · Francisco · 17 de diciembre de 1936. Buenos Aires, Argentina · 21 de abril de 2025 (88 años) Domus Sanctae Marthae, Ciudad del Vaticano.'),\n",
              " SnippetCitation(Url='http://buenosaires.gob.ar/biografiapapafrancisco', Title='El Papa Francisco, su biografía', Snippet='Tras la renuncia de Benedicto XVI, y durante el cónclave, el 13 de marzo de 2013 Jorge Bergoglio fue elegido Papa. Adoptó el nombre de Francisco y desde su ...'),\n",
              " SnippetCitation(Url='https://www.nationalgeographicla.com/historia/2025/05/habemus-papam-leon-xiv-es-el-nuevo-papa-conoce-cuales-son-los-nombres-papales-mas-utilizados-de-la-historia', Title='León XIV es el nuevo papa. Conoce cuáles son los nombres ...', Snippet='León: hasta 2024 hubo 13 papas con este nombre. Robert Francis Prévost, el cardenal elegido como sucesor del papa Francisco, también lo eligió, ...')]"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Paso 3\n",
        "\n",
        "Utilizar GPT para responder a la pregunta.\n",
        "\n",
        "Siguiendo la documentación de la API de OpenAI, escriban una función para generar texto simple\n"
      ],
      "metadata": {
        "id": "A9gPBfR7b9xh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI(api_key=OPENAI_API_KEY)"
      ],
      "metadata": {
        "id": "ZA6RjUKUa03L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  # Uses OPENAI_API_KEY environment variable\n",
        "\n",
        "def chat_complete(\n",
        "    syst: str | None,\n",
        "    user: list[str] = [],\n",
        "    assistant: list[str] = [],\n",
        "    max_tokens: int = 1024,\n",
        "    temperature: float = 0,\n",
        "    model: str = \"gpt-4o\",\n",
        ") -> str:\n",
        "    # Initialize the OpenAI client\n",
        "    messages: list[dict[str, str]] = []\n",
        "\n",
        "    if syst is not None:\n",
        "        messages.append({\"role\": \"system\", \"content\": syst})\n",
        "\n",
        "    for i in range(len(user)):\n",
        "        messages.append({\"role\": \"user\", \"content\": user[i]})\n",
        "        if len(assistant) > i:\n",
        "            messages.append({\"role\": \"assistant\", \"content\": assistant[i]})\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        max_tokens=max_tokens,\n",
        "        temperature=temperature,\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message.content"
      ],
      "metadata": {
        "id": "iwQCl9r6NpQL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_complete(\"Hola\")"
      ],
      "metadata": {
        "id": "oTJJ4KlqeYbK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "78d9c2ed-ff7b-4b3a-a731-554c0c7c941b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'¡Hola! ¿En qué puedo ayudarte hoy?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Paso 4\n",
        "\n",
        "Pensemos un buen prompt que pueda tomar como contexto la información obtenida de SERP API"
      ],
      "metadata": {
        "id": "JbFIFJICfPsM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "SYSTEM_PROMPT = \"\"\"Tu objetivo es responder a la pregunta [PREGUNTA] utilizando este contexto [CONTEXTO].\n",
        "\n",
        "Si la respuesta no se encuentra en el contexto, responde que no sabes. \"\"\"\n"
      ],
      "metadata": {
        "id": "RjLCl-LbedWk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pregunta = \"¿Cual es el nombre del Papa?\""
      ],
      "metadata": {
        "id": "vp7OAn8NfvMV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SYSTEM_PROMPT = SYSTEM_PROMPT.replace(\"[PREGUNTA]\", pregunta)\n",
        "SYSTEM_PROMPT = SYSTEM_PROMPT.replace(\"[CONTEXTO]\", str(serp_res))"
      ],
      "metadata": {
        "id": "NbImV4Qgf2uE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_complete(SYSTEM_PROMPT)"
      ],
      "metadata": {
        "id": "uy0UA0DfgI_x",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "0a48ed92-b23b-43b4-ad3f-527e32662751"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'El nombre del Papa es Francisco, cuyo nombre de nacimiento es Jorge Mario Bergoglio.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Paso 6\n",
        "\n",
        "Darle una forma estructurada a las respuestas.\n",
        "\n",
        "Ahora vamos a adaptar la función chat_complete para recibir como parámetro el schema\n"
      ],
      "metadata": {
        "id": "scDeCPb0TYFQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def limpiar_markdown(content: str):\n",
        "    # Remove markdown code block markers\n",
        "    content = content.strip()\n",
        "    if content.startswith('```json'):\n",
        "        content = content[7:]  # Remove ```json\n",
        "    elif content.startswith('```'):\n",
        "        content = content[3:]   # Remove ```\n",
        "    if content.endswith('```'):\n",
        "        content = content[:-3]  # Remove closing ```\n",
        "    content = content.strip()\n",
        "    return content"
      ],
      "metadata": {
        "id": "iDPMA07dSZNV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def chat_complete(\n",
        "    syst: str | None,\n",
        "    user: list[str] = [],\n",
        "    assistant: list[str] = [],\n",
        "    max_tokens: int = 1024,\n",
        "    temperature: float = 0,\n",
        "    model: str = \"gpt-4o\",\n",
        "    schema: dict | None = None\n",
        ") -> str:\n",
        "    # Initialize the OpenAI client\n",
        "    messages: list[dict[str, str]] = []\n",
        "\n",
        "    if syst is not None:\n",
        "        messages.append({\"role\": \"system\", \"content\": syst})\n",
        "\n",
        "    for i in range(len(user)):\n",
        "        messages.append({\"role\": \"user\", \"content\": user[i]})\n",
        "        if len(assistant) > i:\n",
        "            messages.append({\"role\": \"assistant\", \"content\": assistant[i]})\n",
        "\n",
        "    # Build the request parameters\n",
        "    request_params = {\n",
        "        \"model\": model,\n",
        "        \"messages\": messages,\n",
        "        \"max_tokens\": max_tokens,\n",
        "        \"temperature\": temperature,\n",
        "    }\n",
        "    if schema is not None:\n",
        "        request_params[\"response_format\"] = {\n",
        "            \"type\": \"json_schema\",\n",
        "            \"json_schema\": {\n",
        "                \"name\": \"structured_response\",\n",
        "                \"schema\": schema,\n",
        "                \"strict\": True\n",
        "            }\n",
        "        }\n",
        "    response = client.chat.completions.create(**request_params)\n",
        "    content = response.choices[0].message.content\n",
        "    content = limpiar_markdown(content)\n",
        "    return content\n"
      ],
      "metadata": {
        "id": "oGProC82RiGG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SYSTEM_PROMPT = \"\"\"Tu objetivo es responder a la pregunta [PREGUNTA] utilizando este contexto [CONTEXTO].\n",
        "\n",
        "El formato de salida debe ser un array de json con todas las entidades mencionadas. Cada una representada como un único string del título \"\"\""
      ],
      "metadata": {
        "id": "7Iu23GuzXOIs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pregunta = \"Recomendaciones de series 2025\""
      ],
      "metadata": {
        "id": "dRqCf2OOXZh2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "serp_res = serp_results(pregunta)"
      ],
      "metadata": {
        "id": "8Iw1hcp8XooM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SYSTEM_PROMPT = SYSTEM_PROMPT.replace(\"[PREGUNTA]\", pregunta)\n",
        "SYSTEM_PROMPT = SYSTEM_PROMPT.replace(\"[CONTEXTO]\", str(serp_res))"
      ],
      "metadata": {
        "id": "WmMaZnWhXwx2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ahora representemos en un diccionario un esquema con un array de string\n",
        "RECOMMENDATIONS_SCHEMA = {\n",
        "    \"type\": \"ARRAY\",\n",
        "    \"items\": {\n",
        "        \"type\": \"STRING\"\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "U5pBjffiQ5nk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "json_list = chat_complete(SYSTEM_PROMPT)"
      ],
      "metadata": {
        "id": "nZ4qjvnyX2Gf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "json.loads(json_list)"
      ],
      "metadata": {
        "id": "Cxb4C9QXX3_W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3f94789-8806-4772-f0cc-4b5ffb997c97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"Takopi's Original Sin\",\n",
              " 'Si la vida te da mandarinas',\n",
              " 'The Pitt',\n",
              " 'Efectos secundarios',\n",
              " 'Tierra de',\n",
              " 'The Bear (T4)',\n",
              " 'El Eternauta',\n",
              " 'DanDaDan (T2)',\n",
              " 'M: Il figlio del secolo',\n",
              " 'Daredevil',\n",
              " 'Stranger Things',\n",
              " 'Miércoles',\n",
              " 'Alien',\n",
              " 'Blade Runner']"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Paso 7. Bonus\n",
        "\n",
        "Como extra, hagamos una función que nos indique dónde ver cada una de las series."
      ],
      "metadata": {
        "id": "r2w6JY4wZBxp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "shows = json.loads(json_list)"
      ],
      "metadata": {
        "id": "hoiUSJzFZNHs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_streaming_service(show:str):\n",
        "  SYSTEM_PROMPT = \"\"\"Tu objetivo es responder a la pregunta [PREGUNTA] utilizando este contexto [CONTEXTO].\"\"\"\n",
        "  pregunta = f\"¿Dónde puedo ver la serie {show}?\"\n",
        "  contexto = serp_results(pregunta)\n",
        "  SYSTEM_PROMPT = SYSTEM_PROMPT.replace(\"[PREGUNTA]\", pregunta)\n",
        "  SYSTEM_PROMPT = SYSTEM_PROMPT.replace(\"[CONTEXTO]\", str(contexto))\n",
        "  streaming = chat_complete(SYSTEM_PROMPT)\n",
        "  print(show,\"-->\" ,streaming)\n",
        "  return (show, streaming)"
      ],
      "metadata": {
        "id": "xN8xEtzWZO3e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = []\n",
        "# Hagamos sólo 5 para ahorrar costos\n",
        "for show in shows[:5]:\n",
        "  results.append(get_streaming_service(show))"
      ],
      "metadata": {
        "id": "Qy8HyKlDaM8D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a281f2fa-61e8-4266-fe8e-00c79a3abda4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Takopi's Original Sin --> Puedes ver la serie \"Takopi's Original Sin\" en Crunchyroll. También está disponible en el canal de Crunchyroll en Amazon.\n",
            "Si la vida te da mandarinas --> Puedes ver la serie \"Si la vida te da mandarinas\" en Netflix.\n",
            "The Pitt --> Puedes ver la serie \"The Pitt\" en HBO Max, Hulu y Prime Video.\n",
            "Efectos secundarios --> Puedes ver la serie \"Efectos secundarios\" en streaming en HBO Max y Movistar Plus+ Ficción Total. También está disponible en el canal de HBO Max en Amazon.\n",
            "Tierra de --> Puedes ver la serie \"Tierra de Reyes\" en línea a través de la app de Telemundo para iOS y Android, en tu smart TV (Roku, Fire TV, Apple TV, Samsung), en Hulu y en Prime Video.\n"
          ]
        }
      ]
    }
  ]
}